{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json as JSON\n",
    "\n",
    "#from ipynb.fs.full.InsertsDelComparisons import  map_, INDICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>ks</th>\n",
       "      <th>recipe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-04 03:28:18.613319</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662261900176, 'character': 'Shift'}...</td>\n",
       "      <td>Brown 1 pound of hamburger meat. Drain the gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-04 03:29:37.124556</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662261900176, 'character': 'Shift'}...</td>\n",
       "      <td>1) Brown 1 pound of hamburger meat. Drain the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-04 03:29:47.816111</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662261900176, 'character': 'Shift'}...</td>\n",
       "      <td>1) Brown 1 pound of hamburger meat. Drain the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-04 03:33:03.555075</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662262224600, 'character': '1'}, {'...</td>\n",
       "      <td>1) Cook chicken as desired (boiled, pan seared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-04 03:33:30.062465</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662262224600, 'character': '1'}, {'...</td>\n",
       "      <td>1) Cook chicken as desired (boiled, pan seared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-09-04 03:34:08.666681</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662262224600, 'character': '1'}, {'...</td>\n",
       "      <td>1) Cook chicken as desired (boiled, pan seared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-09-04 03:35:33.869167</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662262452515, 'character': '2'}, {'...</td>\n",
       "      <td>28 oz or so of potatoes cubed\\n1 8oz of cream ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-09-04 03:36:08.454643</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662262452515, 'character': '2'}, {'...</td>\n",
       "      <td>28 oz or so of potatoes cubed\\n1 8oz of cream ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-09-04 03:36:43.142187</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662262452515, 'character': '2'}, {'...</td>\n",
       "      <td>28 oz or so of potatoes cubed\\n1 8oz of cream ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-09-04 14:01:31.746981</td>\n",
       "      <td>55d22025cc2b18000c0b9d9c</td>\n",
       "      <td>[{'time': 1662298866744, 'character': 'I'}, {'...</td>\n",
       "      <td>To serve 4 people (your family!)\\n\\n\\n-You wil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   event_date                   user_id  \\\n",
       "0  2022-09-04 03:28:18.613319  55ae64defdf99b3f864653e7   \n",
       "1  2022-09-04 03:29:37.124556  55ae64defdf99b3f864653e7   \n",
       "2  2022-09-04 03:29:47.816111  55ae64defdf99b3f864653e7   \n",
       "3  2022-09-04 03:33:03.555075  55ae64defdf99b3f864653e7   \n",
       "4  2022-09-04 03:33:30.062465  55ae64defdf99b3f864653e7   \n",
       "5  2022-09-04 03:34:08.666681  55ae64defdf99b3f864653e7   \n",
       "6  2022-09-04 03:35:33.869167  55ae64defdf99b3f864653e7   \n",
       "7  2022-09-04 03:36:08.454643  55ae64defdf99b3f864653e7   \n",
       "8  2022-09-04 03:36:43.142187  55ae64defdf99b3f864653e7   \n",
       "9  2022-09-04 14:01:31.746981  55d22025cc2b18000c0b9d9c   \n",
       "\n",
       "                                                  ks  \\\n",
       "0  [{'time': 1662261900176, 'character': 'Shift'}...   \n",
       "1  [{'time': 1662261900176, 'character': 'Shift'}...   \n",
       "2  [{'time': 1662261900176, 'character': 'Shift'}...   \n",
       "3  [{'time': 1662262224600, 'character': '1'}, {'...   \n",
       "4  [{'time': 1662262224600, 'character': '1'}, {'...   \n",
       "5  [{'time': 1662262224600, 'character': '1'}, {'...   \n",
       "6  [{'time': 1662262452515, 'character': '2'}, {'...   \n",
       "7  [{'time': 1662262452515, 'character': '2'}, {'...   \n",
       "8  [{'time': 1662262452515, 'character': '2'}, {'...   \n",
       "9  [{'time': 1662298866744, 'character': 'I'}, {'...   \n",
       "\n",
       "                                              recipe  \n",
       "0  Brown 1 pound of hamburger meat. Drain the gre...  \n",
       "1  1) Brown 1 pound of hamburger meat. Drain the ...  \n",
       "2  1) Brown 1 pound of hamburger meat. Drain the ...  \n",
       "3  1) Cook chicken as desired (boiled, pan seared...  \n",
       "4  1) Cook chicken as desired (boiled, pan seared...  \n",
       "5  1) Cook chicken as desired (boiled, pan seared...  \n",
       "6  28 oz or so of potatoes cubed\\n1 8oz of cream ...  \n",
       "7  28 oz or so of potatoes cubed\\n1 8oz of cream ...  \n",
       "8  28 oz or so of potatoes cubed\\n1 8oz of cream ...  \n",
       "9  To serve 4 people (your family!)\\n\\n\\n-You wil...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/keystrokes-recipes.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description\n",
    "\n",
    "The platform the users used for writing recipes is a ML based review system on recipes users write. The platform is called __RELEX__ and was designed to study the behavior of users. In fact, the users were tasked with writing three recipes each and they were all divided into 5 groups. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Group 1 | Group 2 | Group 3 | Group 4 | Control Group\n",
    ":---: | :---: | :---: | :---: | :---:\n",
    " Without Reflective Prompts | With Reflective Prompts | Without Reflective Prompts | With Reflective Prompts  | No Prompts\n",
    " Without Adaptive Feedback | Without Adaptive Feedback | With Adaptive Feedback  | With Adaptive Feedback | No Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note some users wrote less than 3 and others wrote more than 3 (at least from what i've seen in the data). We will filter out samples considered as the 4th or 5th recipe.\n",
    "\n",
    "\n",
    "We have 187 users (each represented by a ```user_id```) and 1091 sets of keystrokes.\n",
    "Each set of keystrokes is a users revision on what they wrote previously or the start of a new recipe. What I imagine a scenario is when using the platform:\n",
    "- User x writes a first version of a recipe, clicks finished button (registers as a set of keystrokes in our dataset)\n",
    "- According to his group, the platform may or may not present some suggestions\n",
    "- The user modifies their text and submits again (registers as a second set of keystrokes in our dataset)\n",
    "- If the user is done, starts the second recipe, else revises again and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we define keywords as characters appearing in the dataset that correspond to a keyboard action. We also define ```noisy_punct``` as noisy ponctuation characters that we want to remove from certain analysis we will make. We also copy the original data to a new file we will later modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS = ['Alt', 'ArrowDown', 'ArrowLeft', 'ArrowRight', 'ArrowUp', 'Backspace', 'CapsLock', 'Control', 'Delete', 'End', 'Enter', 'Home', 'Meta', 'PageUp', 'PageDown', 'PrintScreen','Shift', 'Tab']\n",
    "noisy_punct = [',', '.', '-', ':', '(', ')']\n",
    "#create a copy of the dataset to another csv file\n",
    "csv_filename = 'data/keystrokes-recipes-modified.csv'\n",
    "df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```keystrokes-recipes.csv``` is the original data and we keep it in case we want to look back at one moment\n",
    "- ```keystrokes-recipes-modified.csv``` is the modified data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and sorting\n",
    "\n",
    "Our data consists of a csv file with event dates, user ids, keystrokes and the recipes they wrote.\n",
    "We clean all the data by working throught the keystrokes first.\n",
    "\n",
    "* We group the characters into the word written and separate between important keywords typed such as backspace, shift, enter etc. The sequence ['shift', 'p', 'e', 'r'] becomes ['shift', 'per'] \n",
    "* We sort the data by user id then event date to get a better idea of every recipe every student has written and the time they took."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the data\n",
    "\n",
    "The first thing we did was isolate the keystrokes to a new ```json``` file saved in ```data/ks.json```\n",
    "\n",
    "The next step is to group words together and separate them from keywords and we work between each whitespace.\n",
    " \n",
    "So for example this entry: \n",
    "```{'time': 1662252404346, 'character': 'Shift'}, {'time': 1662252404376, 'character': 'f'}, {'time': 1662252404505, 'character': 'i'}, {'time': 16622524046700, 'character': ' '}``` \n",
    "\n",
    "gives the following output: \n",
    "```{'time': 1662252404346, 'word': 'Shift'}, {'time': 1662252404505, 'word': 'fi'}```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keystrokes = df['ks'].values.tolist()\n",
    "keystrokes = list(map(lambda j: ast.literal_eval(j), keystrokes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a white space at the end of each set of keystrokes to facilitate data formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = []\n",
    "for i, s in enumerate(keystrokes):\n",
    "   s = list(filter(lambda _ : _ is not None,s))\n",
    "   last_entry = s[-1]\n",
    "   s.append({\"time\" : last_entry['time'], \"character\": \" \"})\n",
    "   ks.append(s)\n",
    "ks = pd.DataFrame(ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_seq(chars):\n",
    "    return \"\".join(list(filter(lambda _ : _ not in KEYWORDS, chars)))\n",
    "\n",
    "def separate_entry(json_values):\n",
    "    new_data = []\n",
    "    last_whitespace = 0\n",
    "    characters = [arr[1] for arr in json_values]\n",
    "    for i, (time, character) in enumerate(json_values):\n",
    "        if character.isspace():\n",
    "            word = characters[last_whitespace: i]\n",
    "            if not any(i in word for i in KEYWORDS):\n",
    "                new_data.append({'time': time, 'word': \"\".join(word)})\n",
    "            else: \n",
    "                new_data.append({'time': time, 'word': find_seq(word)})\n",
    "            last_whitespace = i+1\n",
    "        elif character in KEYWORDS:\n",
    "            new_data.append({'time': time, 'word': character})\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "new_df = ks\n",
    "arr = []\n",
    "for jsonf in new_df.values:\n",
    "    sub_arr = []\n",
    "    for d in jsonf:\n",
    "        if d is not None:\n",
    "            sub_arr.append([d[\"time\"], d[\"character\"]])\n",
    "    arr.append(sub_arr)\n",
    "\n",
    "result = []\n",
    "for jsonf in arr:\n",
    "    result.append(separate_entry(jsonf))\n",
    "with open(\"data/new_data.json\", \"w\") as f:\n",
    "    JSON.dump(result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, we will format the data for the ```separate_entry``` function and when everything is computed, it dumps all the data in a new json file: ```new_data.json``` in the ```data``` directory.\n",
    "\n",
    "```separate_entry``` computes the words between each space character, all the while separating words from keywords. It uses the function ```find_seq``` to separate the characters from keywords so it allows to isolate words between each whitespaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the CSV file\n",
    "\n",
    "We just modify the keystroke data for each row of the original data in ```keystrokes-recipes.csv``` but apply it to ```keystrokes-recipes-modified.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = pd.read_json('data/new_data.json').values.tolist()\n",
    "\n",
    "for i, json in enumerate(jsons):\n",
    "    jsons[i]= list(filter(lambda _ : _ is not None, json))\n",
    "\n",
    "dframe = df.copy()\n",
    "for i in range(len(jsons)):\n",
    "    dframe.iloc[i]['ks'] = jsons[i]\n",
    "\n",
    "dframe.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting by `user_id` and `event_date`\n",
    "\n",
    "We first sort by user id in order to differentiate behaviour between different people more easily and then by event date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>ks</th>\n",
       "      <th>recipe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-04 03:28:18.613319</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662261900176, 'word': 'Shift'}, {'t...</td>\n",
       "      <td>Brown 1 pound of hamburger meat. Drain the gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-04 03:29:37.124556</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662261900176, 'word': 'Shift'}, {'t...</td>\n",
       "      <td>1) Brown 1 pound of hamburger meat. Drain the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-04 03:29:47.816111</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662261900176, 'word': 'Shift'}, {'t...</td>\n",
       "      <td>1) Brown 1 pound of hamburger meat. Drain the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-04 03:33:03.555075</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662262224842, 'word': 'CapsLock'}, ...</td>\n",
       "      <td>1) Cook chicken as desired (boiled, pan seared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-04 03:33:30.062465</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662262224842, 'word': 'CapsLock'}, ...</td>\n",
       "      <td>1) Cook chicken as desired (boiled, pan seared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-09-04 03:34:08.666681</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662262224842, 'word': 'CapsLock'}, ...</td>\n",
       "      <td>1) Cook chicken as desired (boiled, pan seared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-09-04 03:35:33.869167</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662262452660, 'word': '28'}, {'time...</td>\n",
       "      <td>28 oz or so of potatoes cubed\\n1 8oz of cream ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-09-04 03:36:08.454643</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662262452660, 'word': '28'}, {'time...</td>\n",
       "      <td>28 oz or so of potatoes cubed\\n1 8oz of cream ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-09-04 03:36:43.142187</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "      <td>[{'time': 1662262452660, 'word': '28'}, {'time...</td>\n",
       "      <td>28 oz or so of potatoes cubed\\n1 8oz of cream ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-09-04 14:01:31.746981</td>\n",
       "      <td>55d22025cc2b18000c0b9d9c</td>\n",
       "      <td>[{'time': 1662298866838, 'word': 'Shift'}, {'t...</td>\n",
       "      <td>To serve 4 people (your family!)\\n\\n\\n-You wil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   event_date                   user_id  \\\n",
       "0  2022-09-04 03:28:18.613319  55ae64defdf99b3f864653e7   \n",
       "1  2022-09-04 03:29:37.124556  55ae64defdf99b3f864653e7   \n",
       "2  2022-09-04 03:29:47.816111  55ae64defdf99b3f864653e7   \n",
       "3  2022-09-04 03:33:03.555075  55ae64defdf99b3f864653e7   \n",
       "4  2022-09-04 03:33:30.062465  55ae64defdf99b3f864653e7   \n",
       "5  2022-09-04 03:34:08.666681  55ae64defdf99b3f864653e7   \n",
       "6  2022-09-04 03:35:33.869167  55ae64defdf99b3f864653e7   \n",
       "7  2022-09-04 03:36:08.454643  55ae64defdf99b3f864653e7   \n",
       "8  2022-09-04 03:36:43.142187  55ae64defdf99b3f864653e7   \n",
       "9  2022-09-04 14:01:31.746981  55d22025cc2b18000c0b9d9c   \n",
       "\n",
       "                                                  ks  \\\n",
       "0  [{'time': 1662261900176, 'word': 'Shift'}, {'t...   \n",
       "1  [{'time': 1662261900176, 'word': 'Shift'}, {'t...   \n",
       "2  [{'time': 1662261900176, 'word': 'Shift'}, {'t...   \n",
       "3  [{'time': 1662262224842, 'word': 'CapsLock'}, ...   \n",
       "4  [{'time': 1662262224842, 'word': 'CapsLock'}, ...   \n",
       "5  [{'time': 1662262224842, 'word': 'CapsLock'}, ...   \n",
       "6  [{'time': 1662262452660, 'word': '28'}, {'time...   \n",
       "7  [{'time': 1662262452660, 'word': '28'}, {'time...   \n",
       "8  [{'time': 1662262452660, 'word': '28'}, {'time...   \n",
       "9  [{'time': 1662298866838, 'word': 'Shift'}, {'t...   \n",
       "\n",
       "                                              recipe  \n",
       "0  Brown 1 pound of hamburger meat. Drain the gre...  \n",
       "1  1) Brown 1 pound of hamburger meat. Drain the ...  \n",
       "2  1) Brown 1 pound of hamburger meat. Drain the ...  \n",
       "3  1) Cook chicken as desired (boiled, pan seared...  \n",
       "4  1) Cook chicken as desired (boiled, pan seared...  \n",
       "5  1) Cook chicken as desired (boiled, pan seared...  \n",
       "6  28 oz or so of potatoes cubed\\n1 8oz of cream ...  \n",
       "7  28 oz or so of potatoes cubed\\n1 8oz of cream ...  \n",
       "8  28 oz or so of potatoes cubed\\n1 8oz of cream ...  \n",
       "9  To serve 4 people (your family!)\\n\\n\\n-You wil...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we sort \n",
    "pd.read_csv(csv_filename).sort_values(by=['user_id', 'event_date'], ascending=True).to_csv(csv_filename, index=False)\n",
    "#update the dataframe with which we work with\n",
    "df = pd.read_csv(csv_filename)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ast.literal_eval(df['ks'].values[i]) for i in range(len(df))]\n",
    "with open(\"data/new_data.json\", \"w\") as f:\n",
    "        JSON.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating writing sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use distance metrics between each recipe written and keep the indices to separate the different recipes. This alleviates most of the work from the previous idea -- and is more safe to use -- safer than writing my own algorithm. The previous idea consisted of checking the number of inserts between each revision and check for a spike. We were also going to check the time it took between each submission and consider a recipe as new if the difference was important.\n",
    "\n",
    "We download a glove model (similar to word2vec) which is already trained on wikipedia, where each word is represented as a 50-dimensional vector.\n",
    "\n",
    "We will separate every recipe written in sessions so that we can look what happens at each revision session for every recipe written.\n",
    "\n",
    "The algorithm works recursively. For each recipe it computes the distance with the following recipes until it finds a recipe with which $1 - distance <.995$. When it does find one, it restarts the whole process from the index of said recipe with the accumulator containing the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "import gensim.downloader as api\n",
    "model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucam\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\spatial\\distance.py:699: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe index in data</th>\n",
       "      <th>recipe</th>\n",
       "      <th>user id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Brown 1 pound of hamburger meat. Drain the gre...</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1) Cook chicken as desired (boiled, pan seared...</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>28 oz or so of potatoes cubed\\n1 8oz of cream ...</td>\n",
       "      <td>55ae64defdf99b3f864653e7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>To serve 4 people (your family!)\\n\\n\\n-You wil...</td>\n",
       "      <td>55d22025cc2b18000c0b9d9c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>No Bake Cheesecake recipe\\n\\n\\nServes: Whoever...</td>\n",
       "      <td>55d22025cc2b18000c0b9d9c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  recipe index in data                                             recipe  \\\n",
       "0                    0  Brown 1 pound of hamburger meat. Drain the gre...   \n",
       "1                    3  1) Cook chicken as desired (boiled, pan seared...   \n",
       "2                    6  28 oz or so of potatoes cubed\\n1 8oz of cream ...   \n",
       "3                    9  To serve 4 people (your family!)\\n\\n\\n-You wil...   \n",
       "4                   11  No Bake Cheesecake recipe\\n\\n\\nServes: Whoever...   \n",
       "\n",
       "                    user id  \n",
       "0  55ae64defdf99b3f864653e7  \n",
       "1  55ae64defdf99b3f864653e7  \n",
       "2  55ae64defdf99b3f864653e7  \n",
       "3  55d22025cc2b18000c0b9d9c  \n",
       "4  55d22025cc2b18000c0b9d9c  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(s):\n",
    "    res = \"\"\n",
    "    for i, char in enumerate(list(s)):\n",
    "        if char not in noisy_punct:\n",
    "            res += char    \n",
    "    res = [i.lower() for i in res.split()]\n",
    "    res = list(filter(lambda _ : _ not in noisy_punct, res))\n",
    "    return res\n",
    "\n",
    "def get_vector(s):\n",
    "    \"\"\"\n",
    "    Get the vector representation of a sentence from the model\n",
    "\n",
    "    Args:\n",
    "        s (str): text\n",
    "\n",
    "    \"\"\"\n",
    "    arr = []\n",
    "    for i in preprocess(s):\n",
    "        key = None\n",
    "        try: \n",
    "            key = model[i]\n",
    "            arr.append(key)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    arr = np.array(arr)\n",
    "    return np.sum(arr, axis=0)\n",
    "\n",
    "recipes = df['recipe'].values\n",
    "\n",
    "\n",
    "def compute_recipe_indices(start_index, acc):\n",
    "    \"\"\"\n",
    "    Computes the list of indices where each recipe in the dataset begins\n",
    "    Basically, user 0 writes 3 recipes:\n",
    "    starts writing at t = 0, revises once at t = 1, a second time at t = 2 and \n",
    "    starts a new recipe at t = 3, then this function will return [0, 3] \n",
    "\n",
    "    Args:\n",
    "        start_index (int): index to compare with the other recipes\n",
    "        acc (list(int)): list to return\n",
    "\n",
    "    Returns:\n",
    "        list(int) : list of indices of beginning of each recipe\n",
    "    \"\"\"\n",
    "    if start_index >= 1089:\n",
    "        return acc\n",
    "    vec = get_vector(recipes[start_index])\n",
    "    for i in range(start_index, 1090):\n",
    "        dist = 1 - spatial.distance.cosine(vec, get_vector(recipes[i]))\n",
    "        if dist < .995:\n",
    "            acc.append(i)\n",
    "            return compute_recipe_indices(i, acc)\n",
    "\n",
    "\n",
    "recipes_indices = compute_recipe_indices(0, [0])\n",
    "\n",
    "\"\"\"\n",
    "The algorithm works relatively well and we do have approximately 3 recipes per user (some write less, some write more). \n",
    "However, looking at the data, we see that some recipes are the same at certain indices but the algorithm \n",
    "computes a large distance -- one can argue that perhaps there are so many additions that it increases said distance\n",
    "\n",
    "So looking at the data, I detected several recipes out that need to be removed. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#I looked at the data by hand and tagged these as needing to be removed.\n",
    "recipes_to_remove = [30, 40, 43, 52, 94,151, 166, 184, 212, 238, 248, 256, 268, 274, 301, 318, 334,\n",
    "365, 374, 404, 413, 423, 458, 491, 510, 554, 560, 561, 580, 611, 674, 767, 769, 780, 786, 802, 840, 868, 914, 919, 922, 924,\n",
    "933, 934, 936, 937, 954, 999, 1001, 1014, 1043, 1085]\n",
    "\n",
    "to_add = [95, 107,181 , 202, 251, 261, 388, 404, 529, 559, 596, 688, 793, 830, 879, 881,917, 1001, 1034, 1085]\n",
    "\n",
    "#indices 107 and 251: same recipe but user rewrote we consider them as different recipes\n",
    "for i in recipes_to_remove:\n",
    "    recipes_indices.remove(i)\n",
    "\n",
    "for i in to_add:\n",
    "   recipes_indices.append(i)\n",
    "\n",
    "recipes_indices = sorted(recipes_indices)\n",
    "\n",
    "rec = [df['recipe'][i] for i in recipes_indices]\n",
    "users = [df['user_id'][i] for i in recipes_indices]\n",
    "dframe = pd.DataFrame([recipes_indices, rec, users]).transpose()\n",
    "dframe.columns =['recipe index in data', 'recipe', 'user id']\n",
    "dframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an array of indices at which there is a new recipe.\n",
    "Now we have to map the recipes to the users.\n",
    "The idea is to transform the indices: ```[0,3,6,9,11,12,...]``` $\\rightarrow$ ```[(0, [0,3,6]), (1, [9,11,12]), ... ]```\n",
    "\n",
    "However since not everyone has 3 recipes, we can't simply group every 3 recipes together as that would map some recipes to users that havent written them.\n",
    "What we do instead is use pandas methods that does everything so nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map each user to the index of each recipe they wrote\n",
    "map_ = dframe.groupby('user id')[\"recipe index in data\"].apply(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with the data for the Control group (view group info in `InsertsDelComparisons.ipynb`).\n",
    "For some users, we have that the keystrokes are duplicated for each session. \n",
    "\n",
    "For example, a user at t = 0 has some keystrokes, at t = 1, they have the same keystrokes with additional ones which are the revisions. So we must remove duplicate ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_of_first_attempts_per_user = df.groupby('user_id').head(1).index\n",
    "\n",
    "control_group_indices =[0, 16, 17, 19, 24, 27, 29, 32, 43, 49, 64, 66, 70, 71, 73, 87, 95, 97, 99, 103, 108, \\\n",
    "    111, 118, 119, 122, 124, 126, 127, 136, 139, 141, 146, 150, 154, 158, 164, 168, 175, 183, 185] \n",
    "    # for more info check InsertsDelComparisons.ipynb\n",
    "def compute_recipe_indices(user_index):\n",
    "    recipe_indices = map_[user_index].copy()\n",
    "    if user_index == 186: last_index_where_written = len(df)\n",
    "    else: last_index_where_written = indices_of_first_attempts_per_user[user_index + 1]\n",
    "    recipe_indices.append(last_index_where_written)\n",
    "    return recipe_indices\n",
    "\n",
    "copy = df.copy()\n",
    "seen = {}\n",
    "for user_index in control_group_indices:\n",
    "    indices_where_written = compute_recipe_indices(user_index=user_index)\n",
    "    for index in range(indices_where_written[0], indices_where_written[-1]):\n",
    "        dframe = copy.iloc[index]\n",
    "        for json in ast.literal_eval(dframe['ks']):\n",
    "            entry = (json['time'], json['word'])\n",
    "            if entry not in seen:\n",
    "                seen[entry] = 0\n",
    "         \n",
    "\n",
    "for user_index in control_group_indices:\n",
    "    recipe_indices = compute_recipe_indices(user_index=user_index)\n",
    "    for index in range(recipe_indices[0], recipe_indices[-1]):\n",
    "        new_ks = []\n",
    "        users_ks = ast.literal_eval(copy.iloc[index]['ks'])\n",
    "        for entry in users_ks:\n",
    "            if seen[(entry['time'], entry['word'])] == 0:\n",
    "                new_ks.append(entry)\n",
    "                seen[(entry['time'], entry['word'])] += 1\n",
    "            else: continue\n",
    "        df.iloc[index]['ks'] = new_ks\n",
    "\n",
    "df.to_csv(csv_filename, index=False)\n",
    "df = pd.read_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing useful variables for other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'KEYWORDS' (list)\n",
      "Stored 'noisy_punct' (list)\n",
      "Stored 'ks' (DataFrame)\n",
      "Stored 'map_' (Series)\n",
      "Stored 'recipes_indices' (list)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%store df\n",
    "%store KEYWORDS\n",
    "%store noisy_punct\n",
    "%store ks\n",
    "%store map_\n",
    "%store recipes_indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "034e82c898f96a531aea7f463adf54ed75110b5c8a706bc29f14438863882a0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
