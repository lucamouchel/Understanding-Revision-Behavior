{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"keystrokes-recipes.csv\")\n",
    "KEYWORDS = [\"Shift\", \"Backspace\", \"Enter\", \"ArrowDown\",\n",
    "            \"ArrowLeft\", \"ArrowRight\", \"ArrowUp\", \"End\", \"Control\", \"CapsLock\"]\n",
    "\n",
    "#create a copy of the dataset to another csv file\n",
    "\n",
    "df.to_csv('keystrokes-recipes-modified.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```keystrokes-recipes.csv``` is the original data and we keep it in case we want to look back at one moment\n",
    "- ```keystrokes-recipes-modified.csv``` is the modified data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and sorting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data consists of a csv file with event dates, user ids, keystrokes and the recipes they wrote.\n",
    "We clean all the data by working throught the keystrokes first.\n",
    "\n",
    "* We group the characters into the word written and separate between important keywords typed such as backspace, shift, enter etc. The sequence [\"shift\", \"p\", \"e\", \"r\"] becomes [\"shift\", \"per\"] \n",
    "* We sort by user id to get a better idea of every recipe every student has written."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we did was isolate the keystrokes to a new ```json``` file saved in ```data/all_keystrokes.json```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to group words together and separate them from keywords and we work between each whitespace.\n",
    " \n",
    "So for example this entry: \n",
    "\n",
    "```{'time': 1662252404346, 'character': 'Shift'}, {'time': 1662252404376, 'character': 'f'}, {'time': 1662252404505, 'character': 'i'}``` \n",
    "\n",
    "gives the following output: \n",
    "\n",
    "```{'time': 1662252404346, 'word': 'Shift'}, {'time': 1662252404505, 'word': 'fi'}```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_seq(chars):\n",
    "    return \"\".join(list(filter(lambda _ : _ not in KEYWORDS, chars)))\n",
    "\n",
    "def separate_entry(json_values):\n",
    "    new_data = []\n",
    "    last_whitespace = 0\n",
    "    characters = [arr[1] for arr in json_values]\n",
    "\n",
    "    for i, (time, character) in enumerate(json_values):\n",
    "        if character.isspace():\n",
    "            word = characters[last_whitespace: i]\n",
    "            if not any(i in word for i in KEYWORDS):\n",
    "                new_data.append({'time': time, 'word': \"\".join(word)})\n",
    "            else:\n",
    "                new_data.append({'time': time, 'word': find_seq(word)})\n",
    "            last_whitespace = i+1\n",
    "\n",
    "        elif character in KEYWORDS:\n",
    "            new_data.append({'time': time, 'word': character})\n",
    "        \n",
    "        elif not character:\n",
    "            continue\n",
    "\n",
    "    return new_data\n",
    "\n",
    "def compute():\n",
    "    new_df = pd.DataFrame(pd.read_json(\"data/all_keystrokes.json\"))\n",
    "    arr = []\n",
    "    for jsonf in new_df.values:\n",
    "        sub_arr = []\n",
    "        for d in jsonf:\n",
    "            if d is not None:\n",
    "                sub_arr.append([d[\"time\"], d[\"character\"]])\n",
    "        arr.append(sub_arr)\n",
    "\n",
    "    result = []\n",
    "    for jsonf in arr:\n",
    "        result.append(separate_entry(jsonf))\n",
    "\n",
    "    import json\n",
    "    with open(\"data/new_data.json\", \"w\") as f:\n",
    "        json.dump(result, f)\n",
    "    return\n",
    "\n",
    "compute()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, ``` compute()``` will format the data for the ```separate_entry``` function and when everything is computed, it dumps all the data in a new json file.\n",
    "\n",
    "```separate_entry``` computes the words between each space character, all the while separating words from keywords. It uses the function ```find_seq``` to separate the characters from keywords so it allows to isolate words between each whitespaces.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just modify the keystroke data for each row of the original data in ```keystrokes-recipes.csv``` but apply it to ```keystrokes-recipes-modified.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = pd.read_json(\"data/new_data.json\").values.tolist()\n",
    "\n",
    "for i, json in enumerate(jsons):\n",
    "    jsons[i]= list(filter(lambda _ : _ is not None, json))\n",
    "\n",
    "def write_to_csv_file(filename, recipes_len):\n",
    "    df = pd.read_csv(filename)\n",
    "    for i in range(recipes_len):\n",
    "        df.loc[i,\"ks\"] = jsons[i]\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "\n",
    "#Uncomment only if you are running the notebook for the first time\n",
    "write_to_csv_file(\"keystrokes-recipes-modified.csv\", len(jsons))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting by user id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to sort by user id in order to differentiate behaviour between different people more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = \"keystrokes-recipes-modified.csv\"\n",
    "\n",
    "pd.read_csv(csv_filename).sort_values(by=\"user_id\", ascending=True).to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(sequence=[['Firstly,', 'cut', 'up', 'some', 'chicken', 'breasts', 'into', 'cubes', 'before', 'then', 'dicing', 'one', 'white', 'onion.Next,', 'pour', 'a', 'drizzle', 'of', 'vegetable', 'oil', 'into', 'the', 'pan', 'before', 'placing', 'the', 'chicken', 'into', 'the', 'pan', 'to', 'brown.', 'Season', 'the', 'chicken,', 'whilst', 'continuously', 'stirring', 'until', 'golden.Mix', 'in', 'the', 'white', 'onion,', 'before', 'then', 'adding', 'a', 'tablespoon', 'of', 'garam', 'masala,', 'cumin', 'and', 'cyanne', 'pepper', 'for', 'spice.', 'Continue', 'to', 'stir', 'this', 'for', 'around', '1', 'minute', 'until', 'fragrant.Stir', 'in', 'some', '300ml', 'of', 'coconut', 'milk,', 'as', 'well', 'as', '300ml', 'of', 'tinned', 'chopped', 'tomatos', 'and', 'season', 'to', 'taste.Simmer', 'this', 'for', 'around', '15', 'minutes', 'until', 'the', 'chicken', 'is', 'cooked', 'through,', 'and', 'it', 'has', 'thickened', 'into', 'an', 'flavourful', 'curry.']]), Row(sequence=[['First', 'dice', 'two', 'onions,', 'cut', '2', 'tomatoes', 'and', '3', 'chillies,', 'grate', 'half', 'a', 'garlic', 'and', 'half', 'a', 'ginger.Then', 'measure', 'out', 'half', 'a', 'cup', 'of', 'vegetable', 'oil/healthier', 'option', 'and', 'pour', 'into', 'a', 'big', 'pan.\\xa0Put', 'the', 'diced', 'onions', 'and', 'the', 'ginger', 'and', 'garlic', 'into', 'the', 'pan', 'and', 'wait', 'until', 'they', 'turn', 'golden', 'brown.\\xa0Once', 'golden', 'brown', 'add', 'in', 'half', 'a', 'tin', 'of', 'chopped', 'tomatoes', 'and', 'the', 'two', 'fresh', 'tomatoes.\\xa0Then', 'saute', 'for', '10', 'minutes.\\xa0After', 'saute,', 'add', 'your', 'spices', '-', 'half', 'a', 'tsp', 'of', 'chilli', 'powder,', 'half', 'a', 'tsp', 'of', 'salt', 'and', 'half', 'a', 'tsp', 'of', 'coriander', 'and', 'cumin', 'powder.\\xa0Then', 'saute', 'for', '5', 'minutes', 'with', 'half', 'a', 'glass', 'of', 'water.Once', 'done,', 'add', 'in', '500', 'grams', 'of', 'bonesless', 'chicken,\\xa0Add', 'in', 'half', 'a', 'glass', 'of', 'water', 'as', 'well.\\xa0Then', 'cook', 'on', 'high', 'flame', 'for', '3', 'minutes,', 'then', 'put', 'the', 'lid', 'on', 'and', 'cook', 'for', '30', 'minutes', 'on', 'low', 'flame.\\xa0Garnish', 'with', 'coriander', 'and', 'serve.\\xa0']])]\n",
      "+-------------------------+----+\n",
      "|sequence                 |freq|\n",
      "+-------------------------+----+\n",
      "|[[chopped, and]]         |2   |\n",
      "|[[chopped, until, of]]   |2   |\n",
      "|[[chopped, and, and]]    |2   |\n",
      "|[[chopped, of]]          |2   |\n",
      "|[[chopped, of, and]]     |2   |\n",
      "|[[chopped, of, of]]      |2   |\n",
      "|[[chopped, minutes]]     |2   |\n",
      "|[[chopped, minutes, and]]|2   |\n",
      "|[[chopped, minutes, of]] |2   |\n",
      "|[[chopped, until]]       |2   |\n",
      "+-------------------------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.fpm import PrefixSpan\n",
    "from pyspark.shell import sc\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.types import Row\n",
    "\n",
    "from csv import reader\n",
    "\n",
    "recipes = pd.read_csv('keystrokes-recipes.csv')['recipe'][:2]\n",
    "\n",
    "copy = recipes.copy()\n",
    "copy[0] = Row(sequence=[recipes[0].replace(\"\\n\", \"\").split(\" \")])\n",
    "copy[1] = Row(sequence=[recipes[1].replace(\"\\n\", \"\").split(\" \")])\n",
    "\n",
    "\n",
    "l = [copy[0], copy[1]]\n",
    "print(l)\n",
    "\n",
    "df = sc.parallelize(l).toDF()\n",
    "\n",
    "prefixSpan = PrefixSpan(minSupport=0.1, maxPatternLength=3, maxLocalProjDBSize=32000000)\n",
    "\n",
    "# Find frequent sequential patterns.\n",
    "prefixSpan.findFrequentSequentialPatterns(df).sort(desc(\"freq\")).show(10,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(sequence=[['shrimp', 'almonds', 'avocado', 'vegetables mix'], ['burgers', 'meatballs', 'eggs'], ['chutney'], ['turkey', 'avocado'], ['mineral water', 'milk', 'energy bar', 'whole wheat rice'], ['low fat yogurt']]), Row(sequence=[['whole wheat pasta', 'french fries'], ['soup', 'light cream', 'shallot'], ['frozen vegetables', 'spaghetti', 'green tea'], ['french fries'], ['eggs', 'pet food'], ['cookies']]), Row(sequence=[['turkey', 'burgers', 'mineral water', 'eggs'], ['spaghetti', 'champagne', 'cookies'], ['mineral water', 'salmon'], ['mineral water'], ['shrimp', 'chocolate', 'chicken', 'honey'], ['turkey', 'eggs'], ['turkey', 'fresh tuna', 'tomatoes', 'spaghetti']]), Row(sequence=[['meatballs', 'milk', 'honey', 'french fries'], ['red wine', 'shrimp', 'pasta', 'pepper'], ['rice', 'sparkling water'], ['spaghetti', 'mineral water', 'ham', 'body spray'], ['burgers', 'grated cheese', 'shrimp', 'pasta'], ['eggs']]), Row(sequence=[['parmesan cheese', 'spaghetti', 'soup', 'avocado'], ['ground beef', 'spaghetti', 'mineral water', 'milk'], ['sparkling water'], ['mineral water', 'eggs', 'chicken', 'chocolate']]), Row(sequence=[['spaghetti', 'chocolate', 'brownies', 'white wine'], ['fresh tuna', 'mineral water', 'eggs'], ['spaghetti', 'muffins'], ['spaghetti', 'chocolate'], ['french fries', 'escalope', 'champagne'], ['tomato sauce', 'light mayo'], ['turkey', 'fresh tuna', 'frozen vegetables', 'tomatoes'], ['eggs', 'cookies'], ['soup', 'chicken', 'gums', 'soda'], ['turkey', 'frozen vegetables', 'mineral water', 'cider'], ['spaghetti'], ['clothes accessories']]), Row(sequence=[['energy drink'], ['soup', 'bug spray', 'shallot', 'protein bar'], ['turkey', 'eggs'], ['french fries'], ['chocolate', 'milk']]), Row(sequence=[['herb & pepper', 'whole wheat pasta', 'ground beef', 'mineral water'], ['cookies'], ['shrimp', 'pasta'], ['grated cheese', 'herb & pepper', 'tomatoes', 'tomato sauce'], ['burgers', 'escalope', 'shallot'], ['eggs', 'strawberries'], ['grated cheese', 'ground beef', 'spaghetti', 'mineral water'], ['mint']]), Row(sequence=[['eggs', 'cake', 'french fries'], ['burgers', 'spaghetti', 'milk', 'french fries'], ['mineral water', 'energy bar', 'butter', 'french fries'], ['burgers', 'grated cheese', 'herb & pepper', 'mineral water'], ['energy bar'], ['champagne'], ['burgers', 'almonds', 'eggs', 'french fries'], ['ham', 'soup', 'escalope', 'body spray'], ['turkey', 'ham', 'frozen vegetables', 'pepper'], ['muffins', 'eggs', 'cookies'], ['cookies'], ['frozen vegetables', 'whole wheat pasta', 'ground beef', 'spaghetti'], ['mineral water', 'barbecue sauce', 'chocolate']]), Row(sequence=[['burgers', 'herb & pepper', 'energy bar', 'almonds'], ['turkey', 'burgers', 'ground beef', 'chocolate']]), Row(sequence=[['ham', 'spaghetti', 'chocolate', 'eggs'], ['ground beef', 'energy bar', 'pet food', 'carrots'], ['ground beef', 'tomato sauce', 'spaghetti', 'mineral water'], ['shrimp', 'pasta', 'mineral water', 'eggs'], ['burgers', 'oil', 'tomato juice', 'fresh bread'], ['french wine', 'eggs', 'chocolate', 'low fat yogurt']]), Row(sequence=[['chicken', 'eggs', 'french fries', 'pancakes'], ['turkey', 'herb & pepper', 'salmon', 'white wine'], ['muffins'], ['pasta'], ['tomatoes', 'spaghetti', 'frozen smoothie'], ['ground beef', 'spaghetti', 'milk'], ['french fries'], ['chocolate', 'milk'], ['burgers', 'shrimp', 'pasta', 'frozen vegetables'], ['carrots', 'green tea'], ['chocolate']]), Row(sequence=[['turkey', 'burgers', 'chocolate', 'olive oil'], ['frozen vegetables', 'tomatoes', 'pepper', 'spaghetti'], ['cookies'], ['ground beef'], ['turkey', 'eggs', 'chocolate', 'frozen smoothie'], ['frozen vegetables', 'cooking oil', 'mashed potato'], ['frozen vegetables', 'ground beef', 'tomato sauce', 'mineral water'], ['red wine', 'spaghetti', 'mineral water', 'soup'], ['chocolate', 'tomatoes', 'spaghetti', 'mineral water']]), Row(sequence=[['chocolate', 'shrimp', 'pasta', 'frozen vegetables'], ['turkey', 'shrimp', 'pasta', 'pepper'], ['cookies'], ['turkey', 'tomatoes', 'cake'], ['burgers', 'mineral water', 'milk', 'eggs'], ['mineral water', 'vegetables mix', 'cake', 'frozen smoothie']]), Row(sequence=[['cookies'], ['shrimp', 'pasta', 'chicken', 'chocolate bread'], ['shallot'], ['shrimp', 'pasta', 'spaghetti', 'eggs'], ['burgers'], ['red wine', 'ground beef', 'spaghetti', 'mineral water'], ['burgers', 'grated cheese', 'spaghetti', 'avocado'], ['herb & pepper', 'whole wheat pasta', 'ground beef', 'mineral water']]), Row(sequence=[['shrimp', 'pasta', 'yams', 'milk'], ['butter', 'green tea']]), Row(sequence=[['light mayo'], ['low fat yogurt'], ['herb & pepper', 'shrimp', 'pasta', 'spaghetti'], ['burgers', 'eggs'], ['chocolate', 'mineral water', 'corn', 'cottage cheese'], ['muffins']]), Row(sequence=[['ham', 'french wine', 'escalope'], ['spaghetti', 'milk', 'whole wheat rice', 'mint green tea'], ['chocolate', 'body spray'], ['frozen vegetables', 'french fries', 'hot dogs'], ['frozen vegetables', 'mineral water'], ['chocolate']]), Row(sequence=[['french fries'], ['chocolate'], ['burgers', 'ham', 'red wine'], ['shrimp', 'pasta', 'tomatoes', 'energy bar'], ['green tea'], ['low fat yogurt'], ['turkey', 'spaghetti', 'mineral water', 'soup'], ['turkey', 'eggs'], ['bug spray', 'hot dogs']]), Row(sequence=[['oil'], ['soup', 'energy bar', 'chicken', 'eggs']]), Row(sequence=[['cookies'], ['olive oil', 'cookies', 'mushroom cream sauce'], ['ground beef', 'pancakes', 'cooking oil', 'gluten free bar'], ['mineral water', 'french fries'], ['herb & pepper'], ['salmon'], ['eggs', 'escalope'], ['mineral water', 'tomato juice'], ['mineral water'], ['shrimp', 'mineral water', 'soup', 'black tea'], ['cake', 'frozen smoothie'], ['turkey', 'burgers', 'grated cheese', 'tomatoes'], ['frozen vegetables', 'ground beef', 'mineral water', 'olive oil'], ['turkey', 'burgers', 'ground beef', 'milk']]), Row(sequence=[['whole wheat pasta', 'ground beef', 'spaghetti', 'yams'], ['eggs', 'whole wheat rice', 'cake', 'green tea'], ['ground beef', 'yams', 'soup', 'avocado'], ['milk'], ['spaghetti', 'chocolate'], ['whole wheat pasta', 'honey'], ['whole wheat pasta', 'green tea'], ['spaghetti', 'meatballs', 'vegetables mix', 'chocolate'], ['eggs', 'low fat yogurt'], ['fresh tuna', 'shrimp', 'pasta', 'mineral water'], ['mineral water', 'green grapes', 'hot dogs', 'fresh bread'], ['frozen vegetables', 'meatballs', 'eggs', 'chocolate'], ['chocolate'], ['meatballs', 'milk', 'fresh bread'], ['low fat yogurt'], ['green tea']]), Row(sequence=[['escalope', 'pasta'], ['pepper', 'chocolate', 'olive oil', 'french wine'], ['red wine', 'french wine', 'vegetables mix', 'rice']]), Row(sequence=[['burgers', 'dessert wine', 'spaghetti', 'chicken'], ['french wine', 'cake', 'fresh bread'], ['burgers', 'frozen vegetables', 'flax seed', 'eggs']]), Row(sequence=[['grated cheese', 'shrimp', 'pasta', 'tomatoes'], ['herb & pepper', 'whole wheat pasta', 'olive oil', 'pancakes'], ['spaghetti', 'antioxydant juice'], ['chocolate', 'milk', 'almonds', 'eggs'], ['french fries', 'strawberries'], ['mineral water']]), Row(sequence=[['eggs'], ['escalope'], ['cake'], ['whole wheat pasta', 'antioxydant juice', 'body spray', 'green tea'], ['mineral water', 'oil', 'frozen smoothie'], ['french fries', 'champagne'], ['chocolate', 'french fries']]), Row(sequence=[['herb & pepper', 'ground beef', 'spaghetti', 'eggs'], ['grated cheese', 'muffins', 'tomato juice', 'mayonnaise'], ['whole wheat pasta', 'yams', 'mineral water', 'muffins'], ['burgers', 'spaghetti', 'soup', 'milk']]), Row(sequence=[['chocolate', 'champagne', 'magazines'], ['frozen vegetables', 'spaghetti', 'yams', 'mineral water'], ['tomato sauce', 'chocolate'], ['milk', 'eggs']]), Row(sequence=[['pet food'], ['yogurt cake'], ['green tea'], ['escalope', 'pasta'], ['herb & pepper', 'ground beef'], ['mineral water', 'honey', 'brownies'], ['turkey', 'eggs', 'cake', 'energy drink'], ['turkey', 'burgers', 'dessert wine', 'ground beef'], ['spaghetti', 'mineral water', 'chicken'], ['turkey', 'ground beef', 'carrots', 'french fries']]), Row(sequence=[['fresh tuna', 'barbecue sauce', 'eggplant'], ['energy drink'], ['whole wheat rice', 'french fries', 'hot dogs', 'green tea'], ['mineral water', 'chicken', 'green tea'], ['eggs', 'cake', 'mushroom cream sauce'], ['escalope'], ['antioxydant juice', 'escalope'], ['shrimp', 'spaghetti', 'french fries']])]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.fpm import PrefixSpan\n",
    "from pyspark.shell import sc\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.types import Row\n",
    "\n",
    "from csv import reader\n",
    "\n",
    "# open file in read mode\n",
    "list = []\n",
    "\n",
    "with open(\"store_data2.csv\", 'r') as read_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    csv_reader = reader(read_obj)\n",
    "    customerlist=[]\n",
    "    sequence = []\n",
    "    anotherList=[]\n",
    "    for row in csv_reader:# row variable is a list that represents a row in csv  # print(row)\n",
    "\n",
    "        list2 = []\n",
    "\n",
    "        for x in row:\n",
    "              if x.isdigit():\n",
    "                \n",
    "                if  len(customerlist) == 0 or  customerlist[len(customerlist) - 1] != x:\n",
    "\n",
    "                     if len(customerlist) != 0:\n",
    "                            list.append(Row(sequence=anotherList))\n",
    "\n",
    "                     customerlist.append(x)\n",
    "                     sequence=[]\n",
    "                     anotherList=[]\n",
    "\n",
    "              if x != \"\" and not x.isdigit() :\n",
    "\n",
    "                  list2.append(x)\n",
    "\n",
    "        anotherList.append(list2)\n",
    "\n",
    "\n",
    "list.append(Row(sequence=anotherList))\n",
    "print(list)\n",
    "\n",
    "\n",
    "\n",
    "#df = sc.parallelize(list).toDF()\n",
    "\n",
    "#prefixSpan = PrefixSpan(minSupport=0.1, maxPatternLength=3,\n",
    " #                       maxLocalProjDBSize=32000000)\n",
    "\n",
    "# Find frequent sequential patterns.\n",
    "#prefixSpan.findFrequentSequentialPatterns(df).sort(desc(\"freq\")).show(10,False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "034e82c898f96a531aea7f463adf54ed75110b5c8a706bc29f14438863882a0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
