{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df\n",
    "%store -r KEYWORDS\n",
    "%store -r noisy_punct\n",
    "%store -r ks\n",
    "%store -r map_\n",
    "%store -r indices_of_first_attempts_per_user\n",
    "%store -r sorted_users\n",
    "%store -r INDICES\n",
    "%store -r recipes_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from InsertsDelComparisons import get_data_per_session, data_computation_on_groups\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pm4py\n",
    "from pm4py.visualization.petri_net import  visualizer as pn_vis_factory\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.algo.discovery.alpha import  algorithm as alpha_miner\n",
    "\n",
    "def save_user_session_info_graph(csv_filepath, group_num):\n",
    "    graph_data = csv_filepath\n",
    "    dataframe = pd.read_csv(graph_data, sep=';')\n",
    "    event_log = pm4py.format_dataframe(dataframe, case_id='case_id', activity_key='activity', timestamp_key='timestamp')\n",
    "    event_log = pm4py.convert_to_event_log(dataframe)\n",
    "\n",
    "    new_file = 'xes_format.xes'\n",
    "    pm4py.write_xes(event_log, new_file)\n",
    "    log = pm4py.read_xes(new_file)\n",
    "    net, initial_marking, final_marking = pm4py.discover_petri_net_alpha(log)\n",
    "    performance_dfg, start_activities, end_activities = pm4py.discover_performance_dfg(event_log)\n",
    "    \n",
    "    try:\n",
    "        pm4py.save_vis_performance_dfg(performance_dfg, start_activities, end_activities, 'results/process mining/groupnum{n}.png'.format(n=group_num))\n",
    "    except: print('user only has 1 recipe')\n",
    "\n",
    "#pn_vis_factory(pn_vis_factory.apply(net, initial_marking, final_marking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exporting log, completed traces :: 100%|██████████| 40/40 [00:00<00:00, 7264.75it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 40/40 [00:00<00:00, 4596.50it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_durations(csv_filepath):\n",
    "    dataframe = pd.read_csv(csv_filepath, sep=';')\n",
    "    event_log = pm4py.format_dataframe(dataframe, case_id='case_id', activity_key='activity', timestamp_key='timestamp')\n",
    "    event_log = pm4py.convert_to_event_log(dataframe)\n",
    "\n",
    "    new_file = 'xes_format.xes'\n",
    "    pm4py.write_xes(event_log, new_file)\n",
    "    log = pm4py.read_xes(new_file)\n",
    "    all_case_durations = pm4py.get_all_case_durations(log)\n",
    "    #pm4py.view_performance_spectrum(log, ['1st recipe submitted', 'revision' ,'second recipe submitted', 'revision', 'third recipe submitted'], format=\"png\")\n",
    "    #pm4py.view_performance_spectrum(log, ['1st recipe submitted', 'second recipe submitted' , 'third recipe submitted'], format=\"png\")\n",
    "    performance_dfg = pm4py.discover_eventually_follows_graph(event_log)\n",
    "    \n",
    "    return all_case_durations\n",
    "\n",
    "a = get_durations('data\\processMiningData\\group1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS = [';1st recipe submitted;', ';revision;', ';second recipe submitted;']\n",
    "def format_user_data(user_index, case_id=1):\n",
    "    recipe_indices = map_[user_index].copy()\n",
    "    if user_index == 186: last_index_where_written = 1091\n",
    "    else: last_index_where_written = indices_of_first_attempts_per_user[user_index + 1]\n",
    "    recipe_indices.append(last_index_where_written)\n",
    "\n",
    "    where_in_df = np.where(df['user_id'] == sorted_users[user_index])\n",
    "    first_line = str(case_id) + ACTIONS[0] + df.iloc[where_in_df[0][0]]['event_date']\n",
    "\n",
    "    lines = [first_line]\n",
    "    for i, index in enumerate(range(recipe_indices[0]+1, recipe_indices[-1]+1)):\n",
    "        j = index\n",
    "        is_new_recipe = index in recipe_indices\n",
    "        while not is_new_recipe:\n",
    "            line = ACTIONS[1] + df.iloc[where_in_df[0][i+1]]['event_date']\n",
    "            lines.append(line)\n",
    "            j+=1\n",
    "            if j in recipe_indices: is_new_recipe = True\n",
    "        try:\n",
    "            if index in recipe_indices : lines.append(ACTIONS[2] + df.iloc[where_in_df[0][i+1]]['event_date'])\n",
    "        except: continue\n",
    "        \n",
    "    result = lines\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith(ACTIONS[1]):\n",
    "            result[i] = str(case_id) + line\n",
    "           \n",
    "        elif line.startswith(ACTIONS[2]):\n",
    "            second_recipe_already_submitted = any([ACTIONS[2] in l for l in result[:i]])\n",
    "            if second_recipe_already_submitted:\n",
    "                result[i] = str(case_id) + line.replace('second', 'third') \n",
    "            else : result[i] = str(case_id) + line\n",
    "        \n",
    "    for i, line in enumerate(result):\n",
    "        a = ACTIONS[2].replace('second', 'third')\n",
    "        if line.startswith(str(case_id) + a):\n",
    "            has_submitted_third_recipe = any([a in l for l in result[:i]])\n",
    "            if has_submitted_third_recipe:\n",
    "                result[i] = line.replace('third', 'other') \n",
    "            else : result[i] = line \n",
    "            \n",
    "    \n",
    "    return  pd.DataFrame(sorted(set(result), key=result.index), columns=['case_id;activity;timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exporting log, completed traces :: 100%|██████████| 40/40 [00:00<00:00, 4729.31it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 40/40 [00:00<00:00, 1844.70it/s]\n",
      "exporting log, completed traces :: 100%|██████████| 34/34 [00:00<00:00, 3018.00it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 34/34 [00:00<00:00, 2459.15it/s]\n",
      "exporting log, completed traces :: 100%|██████████| 33/33 [00:00<00:00, 5085.69it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 33/33 [00:00<00:00, 3033.75it/s]\n",
      "exporting log, completed traces :: 100%|██████████| 39/39 [00:00<00:00, 4502.43it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 39/39 [00:00<00:00, 3480.45it/s]\n",
      "exporting log, completed traces :: 100%|██████████| 40/40 [00:00<00:00, 5549.49it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 40/40 [00:00<00:00, 2966.37it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    dframes = []\n",
    "    for j, user in enumerate(INDICES[i]):\n",
    "        A = format_user_data(user_index=user, case_id=j+1)\n",
    "        dframes.append(A)\n",
    "\n",
    "    res = pd.concat(dframes)\n",
    "    path = 'data/processMiningData/group{i}.csv'.format(i=i+1)\n",
    "    res.to_csv(path, index=False)\n",
    "    save_user_session_info_graph(csv_filepath=path, group_num=i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 31, 35, 41, 50, 56, 61, 69, 74, 85, 93, 100, 104, 128, 134, 182], [2, 5, 10, 14, 20, 44, 46, 55, 59, 60, 63, 84, 86, 90, 106, 107, 130, 170], [40, 51, 52, 82, 89, 91, 94, 113, 125, 161, 176, 179], [11, 13, 30, 45, 57, 112, 114, 121, 147, 153, 156], [0, 17, 19, 27, 32, 71, 108, 119, 122, 127, 146, 154, 158, 183]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m     with_at_least_one_revision\u001b[39m.\u001b[39mappend(not_outliers)\n\u001b[0;32m     14\u001b[0m \u001b[39mprint\u001b[39m(with_at_least_one_revision)\n\u001b[1;32m---> 16\u001b[0m max_revisions, means, variances, avr_rev_lengths\u001b[39m=\u001b[39m data_computation_on_groups(\u001b[39m0\u001b[39m, with_at_least_one_revision)\n\u001b[0;32m     17\u001b[0m group_characteristics \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mWith Adaptive Feedback\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mWith Reflective Prompts\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mWith Adaptive Feedback\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mWithout Reflective Prompts\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m     18\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mWithout Adaptive Feedback\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mWith Reflective Prompts\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mWithout Adaptive Feedback\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mWithout Reflective Prompts\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mControl Group\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mNo Adaptive Feedback\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mNo Reflective Prompts\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m6\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "with_at_least_one_revision = []\n",
    "for group in range(0,5):\n",
    "    not_outliers = []\n",
    "    for user_index in INDICES[group]:\n",
    "        sessions = get_data_per_session(user_index)\n",
    "        is_outlier = False\n",
    "        for session in sessions:\n",
    "            if len(session) < 2:\n",
    "                is_outlier = True\n",
    "        if not is_outlier:\n",
    "            not_outliers.append(user_index)\n",
    "    with_at_least_one_revision.append(not_outliers)\n",
    "\n",
    "print(with_at_least_one_revision)\n",
    "\n",
    "max_revisions, means, variances, avr_rev_lengths= data_computation_on_groups(0, with_at_least_one_revision)\n",
    "group_characteristics = [\"With Adaptive Feedback\\nWith Reflective Prompts\", \"With Adaptive Feedback\\nWithout Reflective Prompts\", \n",
    "\"Without Adaptive Feedback\\nWith Reflective Prompts\", \"Without Adaptive Feedback\\nWithout Reflective Prompts\", \"Control Group\\nNo Adaptive Feedback\\nNo Reflective Prompts\"]\n",
    "for group in range(1,6):\n",
    "    text = \\\n",
    "    \"\"\"\n",
    "    Maximum number of revisions: {max}\n",
    "    {mean}\n",
    "    {var}\n",
    "    {revision_length_mean}\n",
    "    \"\"\".format(max=max_revisions[group-1], \n",
    "    mean=r'$\\mu_{revisions}=%.3f$' % (means[group-1]), \n",
    "    var=r'$\\sigma^2_{revisions}=%.3f$' % (variances[group-1]),\n",
    "    revision_length_mean=r'$\\mu_{revision lengths}=%.3f$' % (avr_rev_lengths[group-1])\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "034e82c898f96a531aea7f463adf54ed75110b5c8a706bc29f14438863882a0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
